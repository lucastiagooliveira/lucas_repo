{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-93DTTS7R:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x269a1e64e08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\lucas\\Documents\\lucastiagooliveira\\Study Materials\\Ex_Files_Spark_SQL_DataFrames\\Exercise Files\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_path + \"/location_temp.csv\"\n",
    "df1 = spark.read.format(\"csv\").option(\"header\",\"true\").load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(event_date='03/04/2019 19:48:06', location_id='loc0', temp_celcius='29'),\n",
       " Row(event_date='03/04/2019 19:53:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 19:58:06', location_id='loc0', temp_celcius='28'),\n",
       " Row(event_date='03/04/2019 20:03:06', location_id='loc0', temp_celcius='30'),\n",
       " Row(event_date='03/04/2019 20:08:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 20:13:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 20:18:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 20:23:06', location_id='loc0', temp_celcius='29'),\n",
       " Row(event_date='03/04/2019 20:28:06', location_id='loc0', temp_celcius='32'),\n",
       " Row(event_date='03/04/2019 20:33:06', location_id='loc0', temp_celcius='35')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_no_header = data_path + \"/utilization.csv\"\n",
    "df2 = spark.read.format(\"csv\").option(\"header\",\"false\").option(\"inferSchema\",\"true\").load(file_path_no_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='03/05/2019 08:06:14', _c1=100, _c2=0.57, _c3=0.51, _c4=47),\n",
       " Row(_c0='03/05/2019 08:11:14', _c1=100, _c2=0.47, _c3=0.62, _c4=43),\n",
       " Row(_c0='03/05/2019 08:16:14', _c1=100, _c2=0.56, _c3=0.57, _c4=62),\n",
       " Row(_c0='03/05/2019 08:21:14', _c1=100, _c2=0.57, _c3=0.56, _c4=50),\n",
       " Row(_c0='03/05/2019 08:26:14', _c1=100, _c2=0.35, _c3=0.46, _c4=43),\n",
       " Row(_c0='03/05/2019 08:31:14', _c1=100, _c2=0.41, _c3=0.58, _c4=48),\n",
       " Row(_c0='03/05/2019 08:36:14', _c1=100, _c2=0.57, _c3=0.35, _c4=58),\n",
       " Row(_c0='03/05/2019 08:41:14', _c1=100, _c2=0.41, _c3=0.4, _c4=58),\n",
       " Row(_c0='03/05/2019 08:46:14', _c1=100, _c2=0.53, _c3=0.35, _c4=62),\n",
       " Row(_c0='03/05/2019 08:51:14', _c1=100, _c2=0.51, _c3=0.6, _c4=45)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumnRenamed(\"_c0\",\"event_datatime\")\\\n",
    "         .withColumnRenamed(\"_c1\",\"server_\")\\\n",
    "         .withColumnRenamed(\"_c2\",\"cpu_utilization\")\\\n",
    "         .withColumnRenamed(\"_c4\",\"session_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(event_datatime='03/05/2019 08:06:14', server_=100, cpu_utilization=0.57, _c3=0.51, session_count=47),\n",
       " Row(event_datatime='03/05/2019 08:11:14', server_=100, cpu_utilization=0.47, _c3=0.62, session_count=43),\n",
       " Row(event_datatime='03/05/2019 08:16:14', server_=100, cpu_utilization=0.56, _c3=0.57, session_count=62),\n",
       " Row(event_datatime='03/05/2019 08:21:14', server_=100, cpu_utilization=0.57, _c3=0.56, session_count=50),\n",
       " Row(event_datatime='03/05/2019 08:26:14', server_=100, cpu_utilization=0.35, _c3=0.46, session_count=43),\n",
       " Row(event_datatime='03/05/2019 08:31:14', server_=100, cpu_utilization=0.41, _c3=0.58, session_count=48),\n",
       " Row(event_datatime='03/05/2019 08:36:14', server_=100, cpu_utilization=0.57, _c3=0.35, session_count=58),\n",
       " Row(event_datatime='03/05/2019 08:41:14', server_=100, cpu_utilization=0.41, _c3=0.4, session_count=58),\n",
       " Row(event_datatime='03/05/2019 08:46:14', server_=100, cpu_utilization=0.53, _c3=0.35, session_count=62),\n",
       " Row(event_datatime='03/05/2019 08:51:14', server_=100, cpu_utilization=0.51, _c3=0.6, session_count=45)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+---------------+----+-------------+\n",
      "|     event_datatime|server_|cpu_utilization| _c3|session_count|\n",
      "+-------------------+-------+---------------+----+-------------+\n",
      "|03/05/2019 08:06:14|    100|           0.57|0.51|           47|\n",
      "|03/05/2019 08:11:14|    100|           0.47|0.62|           43|\n",
      "|03/05/2019 08:16:14|    100|           0.56|0.57|           62|\n",
      "|03/05/2019 08:21:14|    100|           0.57|0.56|           50|\n",
      "|03/05/2019 08:26:14|    100|           0.35|0.46|           43|\n",
      "|03/05/2019 08:31:14|    100|           0.41|0.58|           48|\n",
      "|03/05/2019 08:36:14|    100|           0.57|0.35|           58|\n",
      "|03/05/2019 08:41:14|    100|           0.41| 0.4|           58|\n",
      "|03/05/2019 08:46:14|    100|           0.53|0.35|           62|\n",
      "|03/05/2019 08:51:14|    100|           0.51| 0.6|           45|\n",
      "|03/05/2019 08:56:14|    100|           0.32|0.37|           47|\n",
      "|03/05/2019 09:01:14|    100|           0.62|0.59|           60|\n",
      "|03/05/2019 09:06:14|    100|           0.66|0.72|           57|\n",
      "|03/05/2019 09:11:14|    100|           0.54|0.54|           44|\n",
      "|03/05/2019 09:16:14|    100|           0.29| 0.4|           47|\n",
      "|03/05/2019 09:21:14|    100|           0.43|0.68|           66|\n",
      "|03/05/2019 09:26:14|    100|           0.49|0.66|           65|\n",
      "|03/05/2019 09:31:14|    100|           0.64|0.55|           66|\n",
      "|03/05/2019 09:36:14|    100|           0.42| 0.6|           42|\n",
      "|03/05/2019 09:41:14|    100|           0.55|0.59|           63|\n",
      "+-------------------+-------+---------------+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_datatime', 'server_', 'cpu_utilization', '_c3', 'session_count']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_sample = df2.sample(False, fraction  = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+---------------+----+-------------+\n",
      "|     event_datatime|server_|cpu_utilization| _c3|session_count|\n",
      "+-------------------+-------+---------------+----+-------------+\n",
      "|03/05/2019 08:06:14|    100|           0.57|0.51|           47|\n",
      "|03/05/2019 10:26:14|    100|           0.56|0.69|           44|\n",
      "|03/05/2019 10:36:14|    100|           0.62|0.36|           50|\n",
      "|03/05/2019 11:51:14|    100|           0.52|0.68|           41|\n",
      "|03/05/2019 12:11:14|    100|           0.27|0.65|           69|\n",
      "|03/05/2019 13:16:14|    100|           0.55|0.69|           66|\n",
      "|03/05/2019 13:21:14|    100|            0.4|0.55|           43|\n",
      "|03/05/2019 13:26:14|    100|           0.52|0.57|           53|\n",
      "|03/05/2019 13:51:14|    100|           0.41|0.59|           67|\n",
      "|03/05/2019 15:11:14|    100|           0.58|0.54|           49|\n",
      "|03/05/2019 16:01:14|    100|           0.39|0.34|           60|\n",
      "|03/05/2019 16:41:14|    100|           0.56|0.59|           65|\n",
      "|03/05/2019 16:51:14|    100|           0.66|0.35|           64|\n",
      "|03/05/2019 17:21:14|    100|            0.4|0.41|           43|\n",
      "|03/05/2019 17:56:14|    100|           0.33|0.71|           43|\n",
      "|03/05/2019 18:31:14|    100|           0.28|0.72|           57|\n",
      "|03/05/2019 18:46:14|    100|           0.53|0.52|           54|\n",
      "|03/05/2019 19:41:14|    100|           0.49|0.37|           55|\n",
      "|03/05/2019 20:51:14|    100|           0.49| 0.5|           38|\n",
      "|03/05/2019 22:21:14|    100|           0.43|0.43|           40|\n",
      "+-------------------+-------+---------------+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_sort = df2_sample.sort(\"event_datatime\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+---------------+----+-------------+\n",
      "|     event_datatime|server_|cpu_utilization| _c3|session_count|\n",
      "+-------------------+-------+---------------+----+-------------+\n",
      "|03/05/2019 08:06:14|    100|           0.57|0.51|           47|\n",
      "|03/05/2019 08:06:23|    105|           0.54|0.38|           74|\n",
      "|03/05/2019 08:07:19|    137|           0.89|0.31|           65|\n",
      "|03/05/2019 08:07:31|    143|           0.41|0.45|           37|\n",
      "|03/05/2019 08:11:40|    115|            0.6|0.52|           55|\n",
      "|03/05/2019 08:11:54|    124|           0.33|0.75|           41|\n",
      "|03/05/2019 08:11:56|    125|           0.63|0.34|           72|\n",
      "|03/05/2019 08:12:03|    129|           0.74|0.62|           81|\n",
      "|03/05/2019 08:12:09|    132|           0.62|0.63|           59|\n",
      "|03/05/2019 08:12:28|    141|           0.41|0.63|           63|\n",
      "|03/05/2019 08:17:01|    128|           0.42|0.44|           50|\n",
      "|03/05/2019 08:17:25|    140|           0.48|0.36|           62|\n",
      "|03/05/2019 08:17:35|    145|           0.88|0.22|           85|\n",
      "|03/05/2019 08:21:29|    109|           0.74|0.52|           64|\n",
      "|03/05/2019 08:21:40|    115|           0.51| 0.4|           66|\n",
      "|03/05/2019 08:21:53|    123|           0.75|0.25|           95|\n",
      "|03/05/2019 08:22:03|    129|           0.46|0.28|           58|\n",
      "|03/05/2019 08:22:06|    130|           0.63| 0.5|           68|\n",
      "|03/05/2019 08:22:41|    148|           0.74|0.11|           99|\n",
      "|03/05/2019 08:26:36|    113|           0.63|0.31|           95|\n",
      "+-------------------+-------+---------------+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_sort.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(df1[\"location_id\"] == \"loc0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1[\"location_id\"] == \"loc0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1[\"location_id\"] == \"loc1\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|location_id|count|\n",
      "+-----------+-----+\n",
      "|     loc196| 1000|\n",
      "|     loc226| 1000|\n",
      "|     loc463| 1000|\n",
      "|     loc150| 1000|\n",
      "|     loc292| 1000|\n",
      "|     loc311| 1000|\n",
      "|      loc22| 1000|\n",
      "|     loc351| 1000|\n",
      "|     loc370| 1000|\n",
      "|     loc419| 1000|\n",
      "|      loc31| 1000|\n",
      "|     loc305| 1000|\n",
      "|      loc82| 1000|\n",
      "|      loc90| 1000|\n",
      "|     loc118| 1000|\n",
      "|     loc195| 1000|\n",
      "|     loc208| 1000|\n",
      "|      loc39| 1000|\n",
      "|      loc75| 1000|\n",
      "|     loc228| 1000|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby(\"location_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.orderBy(\"location_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------------------+\n",
      "|location_id|avg(temp_celcius)|count(location_id)|\n",
      "+-----------+-----------------+------------------+\n",
      "|     loc196|           29.225|              1000|\n",
      "|     loc226|           25.306|              1000|\n",
      "|     loc463|           23.317|              1000|\n",
      "|     loc150|           32.188|              1000|\n",
      "|     loc292|           29.159|              1000|\n",
      "|     loc311|           24.308|              1000|\n",
      "|      loc22|           28.251|              1000|\n",
      "|     loc351|           28.194|              1000|\n",
      "|     loc370|            29.14|              1000|\n",
      "|     loc419|           29.141|              1000|\n",
      "|      loc31|           25.196|              1000|\n",
      "|     loc305|           27.314|              1000|\n",
      "|      loc82|           27.355|              1000|\n",
      "|      loc90|           23.216|              1000|\n",
      "|     loc118|           24.219|              1000|\n",
      "|     loc195|            27.25|              1000|\n",
      "|     loc208|           26.206|              1000|\n",
      "|      loc39|           25.199|              1000|\n",
      "|      loc75|           23.209|              1000|\n",
      "|     loc228|           27.295|              1000|\n",
      "+-----------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby(\"location_id\").agg({'temp_celcius': \"mean\", \"location_id\": \"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------------------+\n",
      "|location_id|max(temp_celcius)|count(location_id)|\n",
      "+-----------+-----------------+------------------+\n",
      "|     loc196|               36|              1000|\n",
      "|     loc226|               32|              1000|\n",
      "|     loc463|               30|              1000|\n",
      "|     loc150|               39|              1000|\n",
      "|     loc292|               36|              1000|\n",
      "|     loc311|               31|              1000|\n",
      "|      loc22|               35|              1000|\n",
      "|     loc351|               35|              1000|\n",
      "|     loc370|               36|              1000|\n",
      "|     loc419|               36|              1000|\n",
      "|     loc305|               34|              1000|\n",
      "|      loc31|               32|              1000|\n",
      "|     loc118|               31|              1000|\n",
      "|     loc195|               34|              1000|\n",
      "|     loc208|               33|              1000|\n",
      "|      loc82|               34|              1000|\n",
      "|      loc90|               30|              1000|\n",
      "|     loc228|               34|              1000|\n",
      "|      loc39|               32|              1000|\n",
      "|      loc75|               30|              1000|\n",
      "+-----------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby(\"location_id\").agg({'temp_celcius': \"max\", \"location_id\": \"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_s1 = df1.sample(fraction = 0.1, withReplacement = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50107"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_s1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|location_id| avg(temp_celcius)|\n",
      "+-----------+------------------+\n",
      "|     loc196|29.186046511627907|\n",
      "|     loc226|25.359550561797754|\n",
      "|     loc463|23.419642857142858|\n",
      "|     loc150|32.398058252427184|\n",
      "|     loc292|          29.09375|\n",
      "|     loc311|24.213483146067414|\n",
      "|      loc22|28.475247524752476|\n",
      "|     loc351| 28.10576923076923|\n",
      "|     loc370|29.076923076923077|\n",
      "|     loc419| 29.29032258064516|\n",
      "|      loc31|25.547169811320753|\n",
      "|     loc305|27.010526315789473|\n",
      "|      loc82|27.327102803738317|\n",
      "|      loc90|  22.8989898989899|\n",
      "|     loc118|24.274509803921568|\n",
      "|     loc195|              27.2|\n",
      "|     loc208|25.705263157894738|\n",
      "|      loc39|25.276190476190475|\n",
      "|      loc75|23.604166666666668|\n",
      "|     loc228|27.163265306122447|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_s1.groupBy(\"location_id\").agg({\"temp_celcius\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|location_id| avg(temp_celcius)|\n",
      "+-----------+------------------+\n",
      "|       loc0| 29.19607843137255|\n",
      "|       loc1| 27.97345132743363|\n",
      "|      loc10| 25.71578947368421|\n",
      "|     loc100|27.150537634408604|\n",
      "|     loc101|25.388349514563107|\n",
      "|     loc102| 30.65289256198347|\n",
      "|     loc103|25.364485981308412|\n",
      "|     loc104| 26.06741573033708|\n",
      "|     loc105|26.260162601626018|\n",
      "|     loc106|27.053763440860216|\n",
      "|     loc107|33.287234042553195|\n",
      "|     loc108| 32.02105263157895|\n",
      "|     loc109|24.021052631578947|\n",
      "|      loc11|25.305263157894736|\n",
      "|     loc110|26.305882352941175|\n",
      "|     loc111|31.568627450980394|\n",
      "|     loc112|  33.4954128440367|\n",
      "|     loc113| 30.15740740740741|\n",
      "|     loc114|              29.0|\n",
      "|     loc115|23.102040816326532|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_s1.groupBy(\"location_id\").agg({\"temp_celcius\": \"mean\"}).orderBy(\"location_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|       loc0|           29.176|\n",
      "|       loc1|           28.246|\n",
      "|      loc10|           25.337|\n",
      "|     loc100|           27.297|\n",
      "|     loc101|           25.317|\n",
      "|     loc102|           30.327|\n",
      "|     loc103|           25.341|\n",
      "|     loc104|           26.204|\n",
      "|     loc105|           26.217|\n",
      "|     loc106|           27.201|\n",
      "|     loc107|           33.268|\n",
      "|     loc108|           32.195|\n",
      "|     loc109|           24.138|\n",
      "|      loc11|           25.308|\n",
      "|     loc110|           26.239|\n",
      "|     loc111|           31.391|\n",
      "|     loc112|           33.359|\n",
      "|     loc113|           30.345|\n",
      "|     loc114|           29.261|\n",
      "|     loc115|           23.239|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"location_id\").agg({'temp_celcius': 'mean'}).orderBy('location_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.write.csv('df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is A43E-EFE2\n",
      "\n",
      " Directory of C:\\Users\\lucas\\Documents\\lucastiagooliveira\\Study Materials\\Ex_Files_Spark_SQL_DataFrames\\Exercise Files\\CH 03\\begin\\df1.csv\n",
      "\n",
      "08/01/2020  10:52 AM    <DIR>          .\n",
      "08/01/2020  10:52 AM    <DIR>          ..\n",
      "08/01/2020  10:52 AM            33,900 .part-00000-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv.crc\n",
      "08/01/2020  10:52 AM            33,872 .part-00001-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv.crc\n",
      "08/01/2020  10:52 AM            33,872 .part-00002-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv.crc\n",
      "08/01/2020  10:52 AM            18,636 .part-00003-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv.crc\n",
      "08/01/2020  10:52 AM                 8 ._SUCCESS.crc\n",
      "08/01/2020  10:52 AM         4,337,756 part-00000-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv\n",
      "08/01/2020  10:52 AM         4,334,110 part-00001-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv\n",
      "08/01/2020  10:52 AM         4,334,110 part-00002-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv\n",
      "08/01/2020  10:52 AM         2,384,024 part-00003-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv\n",
      "08/01/2020  10:52 AM                 0 _SUCCESS\n",
      "              10 File(s)     15,510,288 bytes\n",
      "               2 Dir(s)  135,264,681,984 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir df1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid parameter - /part-00001-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv\n"
     ]
    }
   ],
   "source": [
    "!more df1.csv/part-00001-517ad3f3-ba83-4661-81a3-c9e2b96d5952-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.write.json('df1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is A43E-EFE2\n",
      "\n",
      " Directory of C:\\Users\\lucas\\Documents\\lucastiagooliveira\\Study Materials\\Ex_Files_Spark_SQL_DataFrames\\Exercise Files\\CH 03\\begin\\df1.json\n",
      "\n",
      "08/01/2020  10:55 AM    <DIR>          .\n",
      "08/01/2020  10:55 AM    <DIR>          ..\n",
      "08/01/2020  10:55 AM            88,824 .part-00000-078fee37-674a-4dac-9e8e-f0d8fb6fe1b6-c000.json.crc\n",
      "08/01/2020  10:55 AM            87,392 .part-00001-078fee37-674a-4dac-9e8e-f0d8fb6fe1b6-c000.json.crc\n",
      "08/01/2020  10:55 AM            87,392 .part-00002-078fee37-674a-4dac-9e8e-f0d8fb6fe1b6-c000.json.crc\n",
      "08/01/2020  10:55 AM            48,076 .part-00003-078fee37-674a-4dac-9e8e-f0d8fb6fe1b6-c000.json.crc\n",
      "08/01/2020  10:55 AM                 8 ._SUCCESS.crc\n",
      "08/01/2020  10:55 AM        11,368,080 part-00000-078fee37-674a-4dac-9e8e-f0d8fb6fe1b6-c000.json\n",
      "08/01/2020  10:55 AM        11,184,800 part-00001-078fee37-674a-4dac-9e8e-f0d8fb6fe1b6-c000.json\n",
      "08/01/2020  10:55 AM        11,184,800 part-00002-078fee37-674a-4dac-9e8e-f0d8fb6fe1b6-c000.json\n",
      "08/01/2020  10:55 AM         6,152,320 part-00003-078fee37-674a-4dac-9e8e-f0d8fb6fe1b6-c000.json\n",
      "08/01/2020  10:55 AM                 0 _SUCCESS\n",
      "              10 File(s)     40,201,692 bytes\n",
      "               2 Dir(s)  135,221,051,392 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir df1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
